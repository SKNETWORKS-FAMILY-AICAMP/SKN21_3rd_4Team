{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf4ba4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb 파일 추출 후 json 추출\n",
    "import nbformat\n",
    "\n",
    "def parse_ipynb(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    content = []\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == 'markdown':\n",
    "            content.append(cell.source)\n",
    "        elif cell.cell_type == 'code':\n",
    "            # 코드는 마크다운 코드 블록으로 감싸서 저장\n",
    "            content.append(f\"```python\\n{cell.source}\\n```\")\n",
    "    \n",
    "    return \"\\n\\n\".join(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e21d720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'01_머신러닝개요.ipynb': '# 인공지능 개요\\n\\n## 인공지능 (AI - Artificial Intelligence) 이란\\n\\n### 지능이란?\\n- 지능: 어떤 문제를 해결하기 위한 지적 활동 능력\\n- 인공지능\\n     - 기계가 사람의 지능을 모방하게 하는 기술\\n     - 규칙기반, 데이터 학습 기반\\n\\n### 정의\\n- 다트머스대학 수학과 교수인 존 매카시(John McCarthy)가 \"지능이 있는 기계를 만들기 위한 과학과 공학\" 이란 논문에서 처음으로 제안(1955년)\\n- 인간의 지능(인지, 추론, 학습 등)을 컴퓨터나 시스템 등으로 만든 것 또는, 만들 수 있는 방법론이나 실현 가능성 등을 연구하는 기술 또는 과학\\n  \\n![image.png](attachment:image.png)  \\n\\n### AGI (Artificial General Intelligence)\\n\\n1. **정의**  \\n   - 인간처럼 **광범위한 지적 과제를 수행할 수 있는 인공지능**  \\n   - 새로운 문제를 마주했을 때도 **사전 학습 없이 유연하게 사고하고, 학습하며, 판단** 가능함  \\n   - 언어 이해, 논리적 추론, 계획 수립, 감정 인식 등 **다양한 인지 기능을 통합적으로 수행**  \\n\\n2. **특징**  \\n   - 하나의 시스템이 **여러 작업을 동시에 수행** 가능 (예: 번역, 추론, 요약, 게임 등)  \\n   - **환경 변화에 적응**하고 **스스로 학습** 가능  \\n   - **자기 인식(self-awareness)**, **창의성**, **목표 설정 능력** 등을 포함할 수 있음  \\n\\n3. **현재 AI와의 차이**  \\n   - 현재 AI(Narrow AI): 특정 목적만 수행 가능  \\n     예) 알파고(바둑), GPT(Chatbot), DALL·E(이미지 생성)  \\n   - AGI: 하나의 시스템으로 **모든 작업**을 수행하는 **범용 지능**  \\n\\n4. **AGI 개발의 어려움**  \\n   - 인간 수준의 **추상적 사고**, **감정 이해**, **윤리 판단** 등을 기술로 구현하기 어려움  \\n   - **데이터 편향**, **안정성**, **설명 가능성** 등의 문제 해결 필요  \\n   - **통제 불가능성** 및 **비의도적 행동**에 대한 우려 존재  \\n\\n5. **AGI가 사회에 미칠 영향**  \\n\\n   - **긍정적 영향**  \\n     - 복잡한 문제 해결 (예: 기후 변화, 신약 개발, 우주 탐사 등)  \\n     - 전 산업의 **생산성 폭증** 및 비용 절감  \\n     - 개인 맞춤형 교육, 의료 서비스의 대중화  \\n\\n   - **부정적 영향**  \\n     - **대규모 일자리 대체**: 사무직, 제조업, 전문가 직종 포함  \\n     - **의사결정 권한의 이전**: 인간 통제 없이 AI가 판단할 위험  \\n     - **불평등 심화**: AGI를 가진 소수 기업 또는 국가의 독점  \\n     - **윤리적·법적 공백**: 책임 소재 불명확, 악용 가능성 존재 \\n\\n### 인공지능(AI) 발전의 주요 원동력\\n\\n1. **데이터 폭증 (Big Data)**  \\n   - 인터넷, 스마트폰, IoT 기기로부터 생성되는 방대한 데이터로 모델을 학습시킬 충분한 데이터가 확보됨.\\n   - 예:  \\n     - 유튜브: 매분 500시간 분량의 영상 업로드  \\n     - 자율주행차: 하루 수 TB의 주행 데이터 생성  \\n2. **컴퓨팅 파워 향상 (GPU, TPU 등)**  \\n   - 병렬 연산에 특화된 GPU, TPU와 같은 하드웨어의 발전\\n3. **딥러닝 알고리즘 혁신**  \\n   - 인공신경망 모델의 구조적 개선 \\n   - 예시:  \\n     - CNN (이미지), RNN/LSTM (시계열), Transformer (언어)와 같은 향상된 알고리즘들이 개발됨.\\n     - 특히 \"Attention is All You Need\" (2017) 논문의 Transformer 모델은 LLM 시대를 열었다.\\n4. **오픈소스 생태계**  \\n   - 누구나 연구, 실험 가능한 AI 프레임워크 등장\\n       - PyTorch, TensorFlow, Hugging Face Transformers   \\n   - 또한 다양한 모델들이 오픈소스로 배포되고 그를 바탕으로 더 발전한 모델들이 나오는 선순환 구조가 만들어짐.  \\n     - Stable Diffusion, LLaMA 등\\n5. **산업계·빅테크의 투자 경쟁**  \\n   - 수십~수백억 달러 단위의 대규모 투자  \\n   - 예:  \\n     - Microsoft가 OpenAI에 130억 달러 이상 투자  \\n     - Google, Meta, Amazon들 AI 전담 조직 확대  \\n6. **생성형 AI 대중화와 사용자 피드백**  \\n   - 일반 사용자들의 인공지능 서비스 사용 피드백이 모델 개선 가속화 함.\\n   - 예시:  \\n     - ChatGPT의 사용자 피드백 → RLHF 기법 발전  \\n     - Midjourney, Runway 등의 이미지·영상 생성 서비스 대중화  \\n\\n## 머신러닝과 딥러닝\\n\\n![image.png](attachment:image.png)\\n<center>출처: [nvida 블로그](https://blogs.nvidia.co.kr/2016/08/03/difference_ai_learning_machinelearning/)</center>\\n\\n### 머신러닝(Machine Learning)\\n- 데이터 학습 기반의 인공 지능 분야\\n- 명시적인 규칙을 프로그래밍하지 않아도, 데이터로부터 패턴을 학습해 예측하거나 분류하는 알고리즘과 기술을 개발하는 인공지능의 한 분야\\n\\n### 딥러닝 (Deep Learning)\\n- 인공신경망 알고리즘을 기반으로 하는 머신러닝의 한 분야. **비정형데이터(영상, 음성, 텍스트)에서 뛰어난 성능**을 나타낸다. 단 학습 데이터의 양이 많아야 한다.\\n\\n> - 비정형 데이터\\n>    - 정해진 규칙 없이 저장되어 값의 의미를 쉽게 파악할 수 없는 데이터\\n>    - 텍스트, 영상, 음성 데이터가 대표적인 예이다.\\n> - 정형 데이터\\n>    - 미리 정해 놓은 형식과 구조에 따라 저장되도록 구성된 데이터\\n>    - 대표적이 예로 관계형 데이터베이스가 있다.\\n\\n# 기존 프로그래밍 방식과 머신러닝 간의 차이\\n![mr_tr](images/01_ml_tr.png)\\n\\n- 전통적인 프로그래밍 방식은 데이터를 처리하는 프로그램(함수, 알고리즘)을 사람이 그 규칙을 찾아 그에 맞게 작성한다.\\n- 머신러닝 방식은 데이터를 처리하는 알고리즘을 주어진 데이터로 부터 컴퓨터가 직접 찾도록 한다.\\n\\n## 머신러닝 모델(알고리즘, 모형)\\n- 모델이란 데이터를 기반으로 입력(Feature)과 출력(Target) 관계를 추정하는 함수를 말한다. 이를 통해 과거 데이터를 이용해 예측(prediction) 또는 추론(inference) 수행\\n    - 머신러닝은 이 모델을 데이터 학습을 통해 정의되도록 한다.\\n    - 데이터 학습이란 \"이 데이터는 이런 패턴을 가졌을 것\"이라고 가정한 일반화된 함수를 정한 뒤 파라미터를 대상 데이터에 맞춰(fitting) 함수를 완성한다. 이 과정을 \"모델을 학습시킨다\" 한다.\\n> 모델(모형)이란 수학, 통계, 머신러닝, 딥러닝 등 다양한 분야에서 사용되며 본질적 의미는 **“현실(또는 데이터)의 구조를 단순화해 표현한 것**을 의미한다.\\n### 모델을 만드는 과정\\n1. 모델을 정하여 수식화 한다. \\n2. 모델을 데이터를 이용해 학습(Train) 시킨다. \\n    - 모델을 데이터의 패턴에 맞춘다. (fit)\\n3. 학습된 모델이 얼마나 데이터 패턴을 잘 표현하는지 평가한다.(Test)\\n\\n![image.png](attachment:image.png)\\n<p>\\n\\n<center><font size=5><b> 머신러닝이란 입력변수와 출력변수간의 패턴(함수)을 데이터학습을 통해 만드는 것</b></font></center>\\n\\n## 데이터 셋 구성\\n### Feature\\n- 추론하기 위한 근거가 되는 값들을 표현하는 용어.\\n- 예측 하거나 분류해야 하는 데이터의 특성, 속성 값을 말한다.\\n- 입력 변수(Input), 독립변수라고도 한다.\\n- 일반적으로 X로 표현한다.\\n\\n### Label\\n- 예측하거나 분류해야 하는 값들을 표현하는 용어\\n- 출력 변수(Output), 종속변수, Target 이라고도 한다.\\n- 일반적으로 y로 표현한다.\\n\\n### 데이터 포인트\\n- 개별 데이터를 표현하는 용어. \\n\\n\\n\\n![image.png](images/01_feature_label_1.png)\\n![image-2.png](images/01_feature_label_2.png)\\n\\n# 머신러닝 알고리즘 분류\\n\\n## 지도학습(Supervised Learning)\\n- 모델에게 데이터의 특징(Feature)와 정답(Label)을 알려주며 학습시킨다.\\n- 대부분의 머신러닝은 지도학습이다.\\n- 지도학습은 분류와 회귀로 나뉜다.\\n\\n- ### 분류(Classification):\\n    - **두개 이상의 클래스(범주)에서 선택을 묻는 지도 학습방법**\\n        - **이진 분류** : 맞는지 틀린지를 분류.\\n        - **다중 분류** : 여러개의 클래스중 하나를 분류\\n- ### 회귀(Regression):\\n    - **숫자(연속된값)를 예측 하는 지도학습**\\n\\n## 비지도학습 (Unsupervised Learning)\\n- **정답이 없이 데이터의 특징만 학습하여 데이터간의 관계를 찾는 학습방법**\\n- ### 군집(Clustering)\\n    - 비슷한 유형의 데이터 그룹을 찾는다. 주로 데이터 경향성을 파악하는 비지도 학습\\n- ### 차원축소(Dimensionality Reduction)\\n    - 예측에 영향을 최대한 주지 않으면서 변수(Feature)를 축소하는 한다.\\n    - 고차원 데이터를 저차원의 데이터로 변환하는 비지도 학습   \\n\\n# 머신러닝 개발 절차 (Machine Learning Process)\\n<br><br>\\n<br>\\n<img align=\"left\" src=\"images/01_crisp.png\">\\n\\n1. Business Understanding\\n    - 머신러닝 개발을 통해 얻고자 하는 것 파악.\\n\\n2. Data Understanding\\n    - 데이터 수집\\n    - 탐색을 통해 데이터 파악\\n\\n3. Data Preparation  \\n    - 데이터 전처리\\n\\n4. Modeling\\n    - 머신러닝 모델 선정\\n    - 모델 학습\\n\\n5. Evaluation\\n    - 모델 평가\\n    - 평가 결과에 따라 위 프로세스 반복\\n\\n6. Deployment\\n    - 평가 결과가 좋으면 실제 업무에 적용\\n\\n# 파이썬 머신러닝,딥러닝 주요 패키지\\n- ### Scikit-learn\\n    - 딥러닝을 제외한 머신러닝 주요 알고리즘 제공\\n- ### Tensorflow\\n    - 구글 브레인 팀이 개발한 텐서플로우는 머신러닝 및 딥러닝 위한 오픈소스 라이브러리다.\\n- ### Keras\\n    - 딥러닝 모델을 쉽게 만들 수 있도록 다양한 딥러닝 플랫폼 위에서 실행되는 고수준 딥러닝 패키지.\\n    - Tensorflow 2.0 부터 keras를 포함하고 있다.\\n- ### Pytorch\\n    - 토치(Torch) 및 카페2(Caffe2) 프레임워크를 기반으로한 페이스북에서 만든 딥러닝 프레임워크\\n\\n# [사이킷런(scikit-learn)](https://scikit-learn.org/stable)\\n파이썬 머신러닝 라이브러리 중 가장 많이 사용된다. 딥러닝을 제외한 대부분의 머신러닝 알고리즘을 제공한다.\\n\\n\\n## 사이킷런의 특징\\n1. 파이썬 기반 다른 머신러닝 라이브러리가 사이킷런 스타일의 API를 지향할 정도로 쉽고 가장 파이썬스런 API 제공\\n2. 머신러닝 관련 다양한 알고리즘을 제공하며 모든 알고리즘에 일관성있는 사용법을 제공한다.\\n\\n## scikit-learn(사이킷런) 설치\\n- `conda install -y scikit-learn`\\n- `pip install scikit-learn`\\n\\n## 사이킷런 주요모듈\\n\\n![image.png](images/scikit-learn_modules.png)',\n",
       " '02_첫번째 머신러닝 분석 - Iris_분석.ipynb': '# Iris(붓꽃) 예측모델\\n![image.png](attachment:image.png)\\n\\n- 프랑스 국화\\n- 꽃말 : 좋은 소식, 잘 전해 주세요, 사랑의 메세지, 변덕스러움\\n\\n## 머신러닝의 Helloworld\\n\\n- 데이터 과학에서 Iris DataSet\\n    - 아이리스 품종 중 Setosa, Versicolor, Virginica 분류에 대한 [**로널드 피셔**](https://ko.wikipedia.org/wiki/%EB%A1%9C%EB%84%90%EB%93%9C_%ED%94%BC%EC%85%94)의  1936년 논문에서 사용된 데이터 셋.\\n    \\n![image.png](attachment:image.png)\\n\\n\\n\\n- 꽃받침(Sepal)과 꽃잎(Petal)의 길이 너비로 세개 품종을 분류\\n![image.png](attachment:image.png)\\n\\n```python\\n# uv pip install scikit-learn pandas matplotlib ipykernel\\n```\\n\\n## 데이터셋 확인하기\\n\\n### scikit-learn 내장 데이터셋 가져오기\\n- scikit-learn은 머신러닝 모델을 테스트 하기위한 데이터셋을 제공한다.\\n    - 이런 데이터셋을 Toy dataset이라고 한다.\\n- 패키지 : sklearn.datasets\\n- 함수   : load_xxxx()\\n\\n### scikit-learn 내장 데이터셋의 구성\\n- scikit-learn의 dataset은 딕셔너리 구조의 Bunch 클래스 객체이다.\\n    - keys() 함수로 key값들을 조회\\n- 구성\\n    - **target_names**: 예측하려는 값(class)을 가진 문자열 배열\\n    - **target**: Label(출력데이터)\\n    - **data**: Feature(입력변수)\\n    - **feature_names**: 입력변수 각 항목의 이름\\n    - **DESCR**: 데이터셋에 대한 설명\\n\\n```python\\nfrom sklearn.datasets import load_iris\\n\\niris = load_iris()\\nprint(type(iris))\\n```\\n\\n```python\\niris.keys() # Dataset 구성 key값들 조회\\n```\\n\\n```python\\n# # 입력변수 조회\\nprint(iris.data.shape)\\niris.data[:3]\\n# iris[\\'data\\']\\n\\n```\\n\\n```python\\n# 입력변수명 조회\\niris[\\'feature_names\\']\\n```\\n\\n```python\\n# 출력변수 조회\\nprint(iris[\\'target\\'].shape)\\niris[\\'target\\']#[:3]\\n```\\n\\n```python\\n# 출력 변수의 class의 의미 조회\\niris[\\'target_names\\']\\n```\\n\\n```python\\nprint(\"--- IRIS Dataset 설명 ---\")\\nprint(iris[\\'DESCR\\'])\\n```\\n\\n## 위 데이터 셋을 판다스 데이터프레임으로 구성\\n- 데이터 프레임 생성 후 데이터 확인\\n  \\n![image.png](attachment:image.png)\\n\\n> - **dataframe/Series.apply(함수)**\\n>     - (dataframe) 함수에 DataFrame의 컬럼(Series)를 전달해서 처리된 값들을 모아 반환\\n>     - (Series) 함수에 원소들을 전달해서 처리된 값들을 모아서 반환\\n>     - 일괄처리시 사용하는 메소드\\n\\n```python\\nimport pandas as pd\\n\\ndf = pd.DataFrame(\\n    iris[\\'data\\'], \\n    columns=iris[\\'feature_names\\']\\n)\\ndf[\\'품종\\'] = iris[\\'target\\']\\ndf.head()\\n```\\n\\n```python\\ndf[\\'품종2\\'] = df[\\'품종\\'].apply(lambda i : iris[\\'target_names\\'][i])\\ndf.head()\\ndf.tail()\\n```\\n\\n```python\\niris[\\'target_names\\']\\n```\\n\\n```python\\ndf.iloc[40:60]\\n```\\n\\n```python\\niris[\\'data\\'].shape\\n```\\n\\n# 머신러닝을 이용한 예측\\n\\n## 문제 정의\\n> 내가 발견한 Iris 꽃받침(Sepal)의 길이(length)와 폭(width)이 각각 5cm, 3.5cm이고 꽃의 꽃잎(Petal)의 길이와 폭은 각각 1.4cm, 0.25cm이 이었다. 이 꽃는 Iris의 무슨 종일까?\\n\\n![image.png](attachment:image.png)\\n\\n### 규칙기반으로 찾아보기\\n\\n- 꽃받침(Sepal)의 길이(length): 5cm, 폭(width): 3.5cm\\n- 꽃잎(Petal) 의 길이(length): 1.4cm, 폭(width): 0.25cm\\n\\n```python\\ndf[(df[\\'sepal length (cm)\\'] == 5) & \\n   (df[\\'sepal width (cm)\\'] ==  3.5) & \\n   (df[\\'petal length (cm)\\'])<1.4]\\n```\\n\\n## 머신러닝 적용\\n\\n### 머신러닝으로 우리가 하려는 것\\n<font size=\\'4\\'><b> 프로그래머가 직접 규칙(패턴)을 만드는  대신 컴퓨터가 데이터를 학습하여 규칙을 자동으로 만들도록 하는 것.</b></font>\\n\\n![image.png](images/01_ml_tr.png)\\n\\n###  결정 트리(Decision Tree) 알고리즘을 이용한 분류\\n#### 결정 트리 알고리즘 개요\\n- 독립 변수의 조건에 따라 종속 변수를 분리 \\n\\n\\n![image.png](images/decision_tree.png)\\n\\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[참조] www.packtpub.com\\n\\n#### 결정트리 모델을 이용해 머신러닝 구현\\n1. import 모델\\n2. 모델 생성\\n3. 모델 학습시키기\\n4. 예측 \\n\\n##### 1. import 모델\\n\\n```python\\nfrom sklearn.tree import DecisionTreeClassifier\\n# xxxxxClassifier: 분류 모델.  xxxxxRegressor : 회귀\\n```\\n\\n##### 2. 모델생성 \\n\\n```python\\nmodel = DecisionTreeClassifier()\\nmodel\\n```\\n\\n##### 3. 모델 학습 시키기\\n\\n```python\\nmodel.fit(iris[\\'data\\'], iris[\\'target\\'])  # 모델.fit(X, y)\\n```\\n\\n```python\\niris[\\'target\\']\\n```\\n\\n```python\\nmodel.predict(iris[\\'data\\'])\\n```\\n\\n##### 4. 예측\\n- 내가 본 iris 꽃의 꽃잎/꽃받침의 길이, 너비를 재서 종류를 예측한다. \\n\\n```python\\nimport numpy as np\\n\\nnew_data = np.array([\\n    [5, 3.5, 1.4, 0.25], \\n    [2, 2.2, 5.3, 2.2], \\n    [1.2, 5, 3.2, 7.6]\\n])\\n# print(new_data.shape)\\n\\npred = model.predict(new_data) # X를 입력해서 y를 예측\\nprint(pred)\\nprint(iris[\\'target_names\\'][pred])\\n```\\n\\n# 그런데 이 결과가 맞을까?\\n\\n- 모델이 추론한 결과가 맞다는 것을 어떻게 보증할 수 있을까?\\n- 모델을 최종 서비스에 적용하기 전에 모델의 성능을 확인하는 작업이 필요하다.\\n\\n## 머신러닝 프로세스\\n\\n![image.png](attachment:image.png)\\n\\n### 훈련데이터셋과 평가(테스트)데이터 분할\\n- 위의 예는 우리가 만든 모델이 성능이 좋은 모델인지 나쁜 모델인지 알 수 없다.\\n- 전체 데이터 셋을 두개의 데이터셋으로 나눠 하나는 모델을 훈련할 때 사용하고 다른 하나는 그 모델을 평가할 때 사용한다.\\n- 보통 훈련데이터와 테스트데이터의 비율은 8:2 또는 7:3 정도로 나누는데 데이터셋이 충분하다면 6:4까지도 나눈다.\\n\\n#### 데이터셋 분할시 주의\\n- 분류 문제의 경우 각 클래스(분류대상)가 같은 비율로 나뉘어야 한다. \\n\\n### scikit-learn의  train_test_split() 함수를 이용해 iris 데이터셋 분할\\n-  train_test_split() : 하나의 데이터셋을 두개의 세트로 분할 하는 함수\\n\\n```python\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(\\n    iris[\\'data\\'],   # input data (X)\\n    iris[\\'target\\'], # output data(y)\\n    test_size=0.2 , # train/test 나눌 비율. test: 0.2, train: 1 - 0.2\\n    stratify=iris[\\'target\\'], # 분류 데이터셋일 경우 넣어주는 설정. iris[\\'target\\'] 의 class 별 구성 비율과 동일한 비율로 나눈다.\\n)\\n```\\n\\n```python\\nprint(iris[\\'data\\'].shape, iris[\\'target\\'].shape) # 원본 shape\\nprint(X_train.shape, y_train.shape) # train set의 shape\\nprint(X_test.shape, y_test.shape)   # test set의 shape\\n```\\n\\n```python\\nnp.unique(iris.target, return_counts=True)\\n```\\n\\n```python\\nnp.unique(y_train, return_counts=True)\\n```\\n\\n```python\\n\\n```\\n\\n### 모델생성\\n\\n```python\\nfrom sklearn.tree import DecisionTreeClassifier\\nmodel2 = DecisionTreeClassifier()\\n```\\n\\n### 모델 학습\\n\\n```python\\nmodel2.fit(X_train, y_train) # train set\\n```\\n\\n### 평가\\n- 머신러닝 평가지표 함수들은 sklearn.metrics 모듈에 있다.\\n- 정확도(accuracy)\\n    - accuracy_score() 함수 이용    \\n    - 전체 예측한 개수 중 맞춘 개수의 비율\\n\\n```python\\nfrom sklearn.metrics import accuracy_score\\n# 모델을 이용해서 추론(예측)\\npred_test = model2.predict(X_test)  # test set으로 평가\\nprint(pred_test.shape) # 모델이 추정한 결과.\\n\\n# 정답, 추정결과를 넣어서 평가.\\nresult = accuracy_score(y_test, pred_test)  # (정답, 모델추정값)\\nprint(\"정확도:\", result) # 정확도: 0 ~ 1 실수\\n```\\n\\n```python\\ny_test\\n```\\n\\n```python\\npred_test\\n```\\n\\n```python\\nnew_data = np.array([\\n    [5, 3.5, 1.4, 0.25], \\n    [2, 2.2, 5.3, 2.2], \\n    [1.2, 5, 3.2, 7.6]\\n])\\nmodel2.predict(new_data)\\n```\\n\\n```python\\n\\n```\\n\\n- **혼동행렬 (Confusion Matrix)** 을 통해 확인\\n    - 모델이 예측한 결과와 실제 정답간의 개수를 표로 제공\\n    - 분류의 평가 지표로 사용된다.\\n    - sklearn.metrics 모듈의 confusion_matrix() 함수 이용\\n    - 결과 ndarray 구조\\n        - axis=0의 index: 정답(실제)의 class \\n        - axis=1의 index: 예측결과의 class\\n        - value: 개수(각 class별 정답/예측한 개수)\\n\\n```python\\nfrom sklearn.metrics import confusion_matrix\\n\\ncm = confusion_matrix(y_test, pred_test)\\n```\\n\\n```python\\ncm\\n```'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict = {}\n",
    "\n",
    "directory_path = \"../data/raw\"\n",
    "for file_name in os.listdir(directory_path):\n",
    "    if file_name.endswith(\".ipynb\"):\n",
    "        result = parse_ipynb(directory_path + \"/\" + file_name)\n",
    "        result_dict[file_name] = result\n",
    "\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a56ccc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_머신러닝개요.ipynb\n",
      "02_첫번째 머신러닝 분석 - Iris_분석.ipynb\n"
     ]
    }
   ],
   "source": [
    "for file_name in result_dict.keys():\n",
    "    result = result_dict[file_name]\n",
    "    print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c7638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
