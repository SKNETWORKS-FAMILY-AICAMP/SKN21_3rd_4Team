# Flask Backend for Bootcamp AI Tutor
# ê¸°ëŠ¥: í•™ìŠµ ì—ì´ì „íŠ¸, ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
# ============================================

# [Flask í•µì‹¬ ëª¨ë“ˆ ì„í¬íŠ¸]
from flask import Flask, render_template, request, jsonify, session, Response
import json
import os
import time
import uuid

# [Flask ì•± ì¸ìŠ¤í„´ìŠ¤ ìƒì„±]
app = Flask(__name__)

# [ë¹„ë°€ í‚¤ ì„¤ì •]
app.secret_key = 'bootcamp-ai-tutor-secret-key-2024'

# ============================================
# ì„¤ì • (Configuration)
# ============================================

# [ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“œ(ì—ì´ì „íŠ¸) ì •ì˜]
MODES = {
    'learning': {'name': 'í•™ìŠµí• ë˜ìš©', 'icon': 'ğŸ“š', 'system_prompt': 'ì¹œì ˆí•œ í•™ìŠµ íŠœí„°ë¡œì„œ ë‹µë³€í•´ì£¼ì„¸ìš”.'},
}


# ============================================
# Agent Functions (Mode-specific logic)
# ============================================


# ============================================
USE_REAL_BACKEND = False  # Trueë¡œ ë³€ê²½í•˜ë©´ ì‹¤ì œ ë°±ì—”ë“œ ì‚¬ìš©
BACKEND_URL = "http://localhost:8000"  # ë°±ì—”ë“œ URL

# [í•™ìŠµ ìë£Œ ê¸°ë°˜ ìƒ˜í”Œ ì‘ë‹µ ë°ì´í„°]
# ì‹¤ì œ ipynb íŒŒì¼ ëª©ë¡ ê¸°ë°˜
SAMPLE_RESPONSES = {
    'ë¨¸ì‹ ëŸ¬ë‹': {
        'text': """## ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ê°œìš”

**ë¨¸ì‹ ëŸ¬ë‹(Machine Learning)**ì€ ì»´í“¨í„°ê°€ ëª…ì‹œì ì¸ í”„ë¡œê·¸ë˜ë° ì—†ì´ ë°ì´í„°ë¡œë¶€í„° í•™ìŠµí•˜ì—¬ íŒ¨í„´ì„ ì°¾ê³  ì˜ˆì¸¡í•˜ëŠ” ì¸ê³µì§€ëŠ¥ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤.

### ì£¼ìš” ê°œë…
1. **ì§€ë„í•™ìŠµ (Supervised Learning)**: ì •ë‹µì´ ìˆëŠ” ë°ì´í„°ë¡œ í•™ìŠµ
   - ë¶„ë¥˜(Classification): ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡
   - íšŒê·€(Regression): ì—°ì†ê°’ ì˜ˆì¸¡

2. **ë¹„ì§€ë„í•™ìŠµ (Unsupervised Learning)**: ì •ë‹µ ì—†ì´ íŒ¨í„´ ë°œê²¬
   - êµ°ì§‘í™”(Clustering): ìœ ì‚¬í•œ ë°ì´í„° ê·¸ë£¹í™”
   - ì°¨ì› ì¶•ì†Œ: ë°ì´í„° ì••ì¶•

3. **ê°•í™”í•™ìŠµ (Reinforcement Learning)**: ë³´ìƒì„ í†µí•œ í•™ìŠµ

### í•™ìŠµ ê³¼ì •
```python
# ê¸°ë³¸ ë¨¸ì‹ ëŸ¬ë‹ ì›Œí¬í”Œë¡œìš°
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# 1. ë°ì´í„° ë¶„ë¦¬
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# 2. ì „ì²˜ë¦¬
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)

# 3. ëª¨ë¸ í•™ìŠµ
model.fit(X_train_scaled, y_train)

# 4. ì˜ˆì¸¡ ë° í‰ê°€
predictions = model.predict(X_test_scaled)
```""",
        'sources': [
            {'type': 'IPYNB', 'title': '01_ë¨¸ì‹ ëŸ¬ë‹ê°œìš”.ipynb', 'content': 'ë¨¸ì‹ ëŸ¬ë‹ ê¸°ì´ˆ ê°œë…'},
            {'type': 'IPYNB', 'title': '02_ì²«ë²ˆì§¸ ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì„ - Iris_ë¶„ì„.ipynb', 'content': 'Iris ë°ì´í„°ì…‹ ì‹¤ìŠµ'}
        ]
    },
    'ì „ì²˜ë¦¬': {
        'text': """## ğŸ“Š ë°ì´í„° ì „ì²˜ë¦¬

ë°ì´í„° ì „ì²˜ë¦¬ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¢Œìš°í•˜ëŠ” í•µì‹¬ ë‹¨ê³„ì…ë‹ˆë‹¤.

### ì£¼ìš” ì „ì²˜ë¦¬ ê¸°ë²•

1. **ê²°ì¸¡ì¹˜ ì²˜ë¦¬**
```python
# ê²°ì¸¡ì¹˜ í™•ì¸
df.isnull().sum()

# í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´
df.fillna(df.mean(), inplace=True)

# í–‰ ì‚­ì œ
df.dropna(inplace=True)
```

2. **ìŠ¤ì¼€ì¼ë§ (ì •ê·œí™”)**
```python
from sklearn.preprocessing import StandardScaler, MinMaxScaler

# í‘œì¤€í™” (Z-score)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Min-Max ì •ê·œí™” (0~1)
minmax = MinMaxScaler()
X_normalized = minmax.fit_transform(X)
```

3. **ì¸ì½”ë”©**
```python
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

# ë¼ë²¨ ì¸ì½”ë”©
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# ì›-í•« ì¸ì½”ë”©
df_encoded = pd.get_dummies(df, columns=['category'])
```

4. **ì´ìƒì¹˜ ì²˜ë¦¬**
- IQR ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ íƒì§€
- Z-score ê¸°ë°˜ ì œê±°""",
        'sources': [
            {'type': 'IPYNB', 'title': '04_ë°ì´í„°_ì „ì²˜ë¦¬.ipynb', 'content': 'ì „ì²˜ë¦¬ ê¸°ë²• ìƒì„¸'},
            {'type': 'IPYNB', 'title': '03_ë°ì´í„°ì…‹ ë‚˜ëˆ„ê¸°ì™€ ëª¨ë¸ê²€ì¦.ipynb', 'content': 'Train/Test ë¶„ë¦¬'}
        ]
    },
    'ê²°ì •íŠ¸ë¦¬': {
        'text': """## ğŸŒ³ ê²°ì •íŠ¸ë¦¬ì™€ ëœë¤í¬ë ˆìŠ¤íŠ¸

### ê²°ì •íŠ¸ë¦¬ (Decision Tree)
ë°ì´í„°ë¥¼ íŠ¹ì • ê¸°ì¤€ìœ¼ë¡œ ë¶„í• í•˜ì—¬ íŠ¸ë¦¬ êµ¬ì¡°ë¡œ ë¶„ë¥˜/ì˜ˆì¸¡í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

```python
from sklearn.tree import DecisionTreeClassifier

# ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
dt = DecisionTreeClassifier(max_depth=5, random_state=42)
dt.fit(X_train, y_train)

# ì˜ˆì¸¡
predictions = dt.predict(X_test)
```

**ì¥ì **: í•´ì„ì´ ì‰¬ì›€, ì „ì²˜ë¦¬ ì ìŒ
**ë‹¨ì **: ê³¼ì í•© ìœ„í—˜

---

### ëœë¤í¬ë ˆìŠ¤íŠ¸ (Random Forest)
ì—¬ëŸ¬ ê²°ì •íŠ¸ë¦¬ë¥¼ ì•™ìƒë¸”í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

```python
from sklearn.ensemble import RandomForestClassifier

# 100ê°œì˜ íŠ¸ë¦¬ë¡œ ì•™ìƒë¸”
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# íŠ¹ì„± ì¤‘ìš”ë„ í™•ì¸
importance = rf.feature_importances_
```

**í•µì‹¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°**:
- `n_estimators`: íŠ¸ë¦¬ ê°œìˆ˜
- `max_depth`: ìµœëŒ€ ê¹Šì´
- `min_samples_split`: ë¶„í•  ìµœì†Œ ìƒ˜í”Œ ìˆ˜""",
        'sources': [
            {'type': 'IPYNB', 'title': '09_ê²°ì •íŠ¸ë¦¬ì™€ ëœë¤í¬ë ˆìŠ¤íŠ¸.ipynb', 'content': 'íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸'},
            {'type': 'IPYNB', 'title': '10_ì•™ìƒë¸”_ë¶€ìŠ¤íŒ….ipynb', 'content': 'ì•™ìƒë¸” ê¸°ë²•'}
        ]
    },
    'ë”¥ëŸ¬ë‹': {
        'text': """## ğŸ§  ë”¥ëŸ¬ë‹ ê¸°ì´ˆ

ë”¥ëŸ¬ë‹ì€ ì¸ê³µì‹ ê²½ë§ì„ ì—¬ëŸ¬ ì¸µìœ¼ë¡œ ìŒ“ì•„ ë³µì¡í•œ íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.

### ì‹ ê²½ë§ì˜ ê¸°ë³¸ êµ¬ì¡°

```
ì…ë ¥ì¸µ â†’ ì€ë‹‰ì¸µ(ë“¤) â†’ ì¶œë ¥ì¸µ
  â†“         â†“          â†“
íŠ¹ì„±ê°’    ê°€ì¤‘ì¹˜ ì—°ì‚°    ì˜ˆì¸¡ê°’
```

### í•µì‹¬ ê°œë…

1. **ë‰´ëŸ°ê³¼ í™œì„±í™” í•¨ìˆ˜**
```python
# í™œì„±í™” í•¨ìˆ˜ ì˜ˆì‹œ
import numpy as np

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def relu(x):
    return np.maximum(0, x)
```

2. **ê²½ì‚¬í•˜ê°•ë²• (Gradient Descent)**
- ì†ì‹¤ í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
- í•™ìŠµë¥ (learning rate)ì´ ì¤‘ìš”

3. **ì—­ì „íŒŒ (Backpropagation)**
- ì¶œë ¥ì¸µì—ì„œ ì…ë ¥ì¸µ ë°©í–¥ìœ¼ë¡œ ì˜¤ì°¨ ì „íŒŒ
- ì²´ì¸ë£°(Chain Rule)ì„ ì´ìš©í•œ ë¯¸ë¶„

### ê°„ë‹¨í•œ ì‹ ê²½ë§ ì˜ˆì‹œ
```python
from sklearn.neural_network import MLPClassifier

mlp = MLPClassifier(
    hidden_layer_sizes=(100, 50),  # ì€ë‹‰ì¸µ êµ¬ì¡°
    activation='relu',
    max_iter=500
)
mlp.fit(X_train, y_train)
```""",
        'sources': [
            {'type': 'IPYNB', 'title': '13_ì„ í˜•ëª¨ë¸_ë¡œì§€ìŠ¤í‹±íšŒê·€.ipynb', 'content': 'DEEPLEARNING ê¸°ì´ˆ'},
            {'type': 'IPYNB', 'title': '11_ìµœì í™”-ê²½ì‚¬í•˜ê°•ë²•.ipynb', 'content': 'ê²½ì‚¬í•˜ê°•ë²• ì›ë¦¬'}
        ]
    }
}


def learning_agent(message, context=None):
    """
    í•™ìŠµìš© ì—ì´ì „íŠ¸
    
    [ë°±ì—”ë“œ ì—°ê²° ë°©ë²•]
    USE_REAL_BACKEND = Trueë¡œ ì„¤ì • í›„,
    BACKEND_URLì˜ /chat ì—”ë“œí¬ì¸íŠ¸ë¡œ ìš”ì²­ì„ ë³´ë‚´ë„ë¡ ìˆ˜ì •í•˜ì„¸ìš”.
    """
    
    # ì‹¤ì œ ë°±ì—”ë“œ ì‚¬ìš© ì‹œ
    if USE_REAL_BACKEND:
        try:
            import requests
            response = requests.post(
                f"{BACKEND_URL}/chat",
                json={"message": message, "context": context},
                timeout=30
            )
            return response.json()
        except Exception as e:
            return {
                'text': f"âš ï¸ ë°±ì—”ë“œ ì—°ê²° ì˜¤ë¥˜: {str(e)}\n\në°±ì—”ë“œ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.",
                'sources': [],
                'steps': [{'step': 1, 'title': 'ì˜¤ë¥˜ ë°œìƒ', 'desc': 'ë°±ì—”ë“œ ì—°ê²° ì‹¤íŒ¨'}]
            }
    
    # ìƒ˜í”Œ ì‘ë‹µ ëª¨ë“œ (ë°±ì—”ë“œ ì—°ê²° ì „)
    message_lower = message.lower()
    
    for keyword, response in SAMPLE_RESPONSES.items():
        if keyword in message_lower or keyword in message:
            return {
                'text': response['text'],
                'sources': response['sources'],
                'steps': [
                    {'step': 1, 'title': 'ì§ˆë¬¸ ë¶„ì„', 'desc': f'"{message}" ì§ˆë¬¸ íŒŒì•…'},
                    {'step': 2, 'title': 'ìë£Œ ê²€ìƒ‰', 'desc': 'ê´€ë ¨ ipynb íŒŒì¼ íƒìƒ‰'},
                    {'step': 3, 'title': 'ë‹µë³€ ìƒì„±', 'desc': 'í•™ìŠµ ìë£Œ ê¸°ë°˜ ì„¤ëª… ì‘ì„±'}
                ]
            }
    
    # ê¸°ë³¸ ì‘ë‹µ
    return {
        'text': f"""## ğŸ“š í•™ìŠµ ë„ìš°ë¯¸

**"{message}"**ì— ëŒ€í•´ ì•Œë ¤ë“œë¦´ê²Œìš”!

í˜„ì¬ ë‹¤ìŒ ì£¼ì œë“¤ì— ëŒ€í•œ í•™ìŠµ ìë£Œê°€ ì¤€ë¹„ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

| ì£¼ì œ | ê´€ë ¨ íŒŒì¼ |
|:---|:---|
| ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ê°œìš” | 01_ë¨¸ì‹ ëŸ¬ë‹ê°œìš”.ipynb |
| ğŸ“Š ë°ì´í„° ì „ì²˜ë¦¬ | 04_ë°ì´í„°_ì „ì²˜ë¦¬.ipynb |
| ğŸŒ³ ê²°ì •íŠ¸ë¦¬/ëœë¤í¬ë ˆìŠ¤íŠ¸ | 09_ê²°ì •íŠ¸ë¦¬ì™€ ëœë¤í¬ë ˆìŠ¤íŠ¸.ipynb |
| ğŸ§  ë”¥ëŸ¬ë‹ ê¸°ì´ˆ | 13_ì„ í˜•ëª¨ë¸_ë¡œì§€ìŠ¤í‹±íšŒê·€.ipynb |
| ğŸ“ˆ í‰ê°€ì§€í‘œ | 05_í‰ê°€ì§€í‘œ.ipynb |
| ğŸ”§ SVM | 07_ì§€ë„í•™ìŠµ_SVM.ipynb |

ìœ„ ì£¼ì œ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì„œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”! ğŸ˜Š""",
        'sources': [
            {'type': 'INFO', 'title': 'í•™ìŠµ ìë£Œ ì•ˆë‚´', 'content': '14ê°œ ipynb íŒŒì¼ ê¸°ë°˜'}
        ],
        'steps': [
            {'step': 1, 'title': 'ì§ˆë¬¸ ë¶„ì„', 'desc': f'"{message}" ì§ˆë¬¸ íŒŒì•…'},
            {'step': 2, 'title': 'ìë£Œ ê²€ìƒ‰', 'desc': 'ê´€ë ¨ í•™ìŠµ ìë£Œ íƒìƒ‰'},
            {'step': 3, 'title': 'ë‹µë³€ ìƒì„±', 'desc': 'ê°€ì´ë“œ ì•ˆë‚´'}
        ]
    }


def get_agent_response(mode, message, context=None):
    """ëª¨ë“œì— ë”°ë¼ ì ì ˆí•œ ì—ì´ì „íŠ¸ í˜¸ì¶œ"""
    return learning_agent(message, context)


# ============================================
# ë¼ìš°íŠ¸ (Routes) - URL ì—”ë“œí¬ì¸íŠ¸ ì •ì˜
# ============================================

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return render_template('index.html', modes=MODES)


@app.route('/chat', methods=['POST'])
def chat():
    """ì±„íŒ… API - POST /chat"""
    data = request.get_json()
    message = data.get('message', '')
    mode = data.get('mode', 'learning')
    
    # ì—ì´ì „íŠ¸ì—ì„œ ì‘ë‹µ ìƒì„±
    response = get_agent_response(mode, message)
    
    return jsonify({
        'answer': response['text'],
        'sources': response['sources'],
        'steps': response['steps']
    })


@app.route('/chat/stream', methods=['POST'])
def chat_stream():
    """ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… API - POST /chat/stream"""
    data = request.get_json()
    message = data.get('message', '')
    mode = data.get('mode', 'learning')
    
    # ì—ì´ì „íŠ¸ ì‘ë‹µ ìƒì„±
    response = get_agent_response(mode, message)
    
    def generate():
        # 1ë‹¨ê³„: ì§„í–‰ ë‹¨ê³„ ì •ë³´ ì „ì†¡
        for step in response['steps']:
            yield f"data: {json.dumps({'type': 'step', 'data': step})}\n\n"
            time.sleep(0.5)
        
        # 2ë‹¨ê³„: ë‹µë³€ì„ ê¸€ì í•˜ë‚˜ì”© ì „ì†¡
        for char in response['text']:
            yield f"data: {json.dumps({'type': 'char', 'data': char})}\n\n"
            time.sleep(0.02)
        
        # 3ë‹¨ê³„: ì°¸ê³  ìë£Œ ì „ì†¡
        yield f"data: {json.dumps({'type': 'sources', 'data': response['sources']})}\n\n"
        
        # 4ë‹¨ê³„: ì™„ë£Œ ì‹ í˜¸
        yield f"data: {json.dumps({'type': 'done'})}\n\n"
    
    return Response(generate(), mimetype='text/event-stream')


@app.route('/reset', methods=['POST'])
def reset_all():
    """ì „ì²´ ì„¸ì…˜ ì´ˆê¸°í™”"""
    session.clear()
    return jsonify({'success': True, 'message': 'Session reset'})


@app.route('/modes')
def get_modes():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“œ ëª©ë¡"""
    return jsonify(MODES)


# ============================================
# ì•± ì‹¤í–‰
# ============================================

if __name__ == '__main__':
    app.run(debug=True, port=5000)
