"""
ì‘ì„±ì : ì‹ ì§€ìš©
Search Agent Role A - Search Router/Strategy

ì´ ëª¨ë“ˆì˜ ì—­í• :
- ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ì•„ì„œ ë¶„ì„
- ì–´ë””ì„œ ê²€ìƒ‰í• ì§€ ê²°ì • (lecture DB, python_doc DB, ë˜ëŠ” ë‘˜ ë‹¤)
- ëª‡ ê°œì˜ ë¬¸ì„œë¥¼ ê²€ìƒ‰í• ì§€ ê²°ì •
- ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ ê²€ìƒ‰í• ì§€ ê²°ì • (similarity, mmr)
- ìµœì¢… ê²€ìƒ‰ ì„¤ì •ì„ ì£¼ì›ë‹˜ ì—ê²Œ ì „ë‹¬

í•µì‹¬ ê°œë…: ì™„ì „ LLM ê¸°ë°˜
- LLM(GPT-4o-mini)ì´ ëª¨ë“  íŒë‹¨ì„ ìˆ˜í–‰
- Structured Outputìœ¼ë¡œ ì•ˆì •ì ì¸ ë°ì´í„° ë°˜í™˜
"""

import os
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (OPENAI_API_KEY ë“±)
load_dotenv()

# torch ë¡œë”© ë¬¸ì œ í•´ê²° (Python 3.13 í˜¸í™˜ì„±)
# Warning ë©”ì‹œì§€ë¥¼ ìˆ¨ê¸°ê³  ë³‘ë ¬ ì²˜ë¦¬ ê´€ë ¨ ì´ìŠˆ ë°©ì§€
os.environ["TRANSFORMERS_NO_ADVISORY_WARNINGS"] = "1"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

from typing import Dict, List, Literal
from langchain_openai import ChatOpenAI  # OpenAI LLM ì¸í„°í˜ì´ìŠ¤
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate
from pydantic import BaseModel, Field    # ë°ì´í„° ê²€ì¦ ë° êµ¬ì¡°í™”
from src.agent.prompts import PROMPTS


def build_search_config(query: str) -> Dict:
    """
    LLMì„ í™œìš©í•˜ì—¬ ì§ˆë¬¸ ë¶„ì„ ë° ê²€ìƒ‰ ì„¤ì •ì„ í•œ ë²ˆì— ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        
    Returns:
        {
            'sources': List[str],           # ê²€ìƒ‰ ëŒ€ìƒ: ['lecture'], ['python_doc'], ë˜ëŠ” ë‘˜ ë‹¤
            'top_k': int,                   # ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜
            'search_method': str,           # 'similarity' ë˜ëŠ” 'mmr'
            'filters': Dict                 # ë©”íƒ€ë°ì´í„° í•„í„° (í–¥í›„ í™•ì¥)
        }
    """
    # ============================================================
    # 1ë‹¨ê³„: Pydantic ëª¨ë¸ ì •ì˜ (LLMì˜ ì¶œë ¥ í˜•ì‹ ê°•ì œ)
    # ============================================================
    # Pydanticì€ ë°ì´í„° ê²€ì¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” LLMì´ ë°˜í™˜í•  JSONì˜ êµ¬ì¡°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
    # ì´ë ‡ê²Œ í•˜ë©´ LLMì´ í•­ìƒ ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ê²Œ ë©ë‹ˆë‹¤.
    
    class SearchConfig(BaseModel):
        # ì§ˆë¬¸ ìœ í˜• (3ê°€ì§€ ì¤‘ í•˜ë‚˜ë§Œ ê°€ëŠ¥)
        query_type: Literal['concept', 'code', 'syntax'] = Field(
            description="ì§ˆë¬¸ íƒ€ì…: concept(ê°œë… ì„¤ëª…), code(ì½”ë“œ ì‘ì„±/ë””ë²„ê¹…), syntax(ë¬¸ë²•)"
        )
        
        # ì§ˆë¬¸ì—ì„œ ì¶”ì¶œí•œ ì£¼ìš” í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        # ì˜ˆ: "RAGì™€ pandas í™œìš©ë²•" â†’ ['rag', 'pandas']
        topic_keywords: List[str] = Field(
            description="ì§ˆë¬¸ì—ì„œ ì¶”ì¶œëœ ì£¼ìš” ê¸°ìˆ  í‚¤ì›Œë“œ (ì˜ˆ: rag, python, pandas, iris)"
        )
        
        # ì§ˆë¬¸ì˜ ë‚œì´ë„ (3ê°€ì§€ ì¤‘ í•˜ë‚˜)
        # ì´ì— ë”°ë¼ ê²€ìƒ‰ ê°œìˆ˜(top_k)ê°€ ìë™ ê²°ì •ë©ë‹ˆë‹¤
        complexity: Literal['basic', 'intermediate', 'advanced'] = Field(
            description="ì§ˆë¬¸ì˜ ë‚œì´ë„: basic(ê¸°ì´ˆ), intermediate(ì¤‘ê¸‰), advanced(ê³ ê¸‰)"
        )
        
        # ê²€ìƒ‰í•  ë°ì´í„° ì†ŒìŠ¤ (í•µì‹¬!)
        # ['lecture']: ML ê°•ì˜ë§Œ
        # ['python_doc']: Python ë¬¸ì„œë§Œ
        # ['lecture', 'python_doc']: ë‘˜ ë‹¤ (ë³µí•© ì§ˆë¬¸)
        search_sources: List[Literal['lecture', 'python_doc']] = Field(
            description="ê²€ìƒ‰í•  ë°ì´í„° ì†ŒìŠ¤ ëª©ë¡. lecture(ê°•ì˜ ìë£Œ), python_doc(Python ê³µì‹ ë¬¸ì„œ)"
        )
        
        # ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜ (1~10 ë²”ìœ„)
        # ge=1: greater than or equal (1 ì´ìƒ)
        # le=10: less than or equal (10 ì´í•˜)
        top_k: int = Field(
            description="ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜. basic: 3ê°œ, intermediate: 5ê°œ, advanced: 7ê°œ",
            ge=1,
            le=10
        )
        
        # ê²€ìƒ‰ ë°©ë²• (2ê°€ì§€ ì¤‘ í•˜ë‚˜)
        # similarity: ë‹¨ìˆœ ìœ ì‚¬ë„ (ë¹ ë¦„)
        # mmr: Maximum Marginal Relevance (ë‹¤ì–‘ì„± ê³ ë ¤, ëŠë¦¼)
        search_method: Literal['similarity', 'mmr'] = Field(
            description="ê²€ìƒ‰ ë°©ë²•. similarity(ë‹¨ìˆœ ìœ ì‚¬ë„), mmr(ë‹¤ì–‘ì„± ê³ ë ¤, ê³ ê¸‰ ì§ˆë¬¸ì— ì í•©)"
        )
    
    # ============================================================
    # 2ë‹¨ê³„: LangChain Chain ìƒì„± (ì²´ì¸í™”)
    # ============================================================
    # ChatPromptTemplate: í”„ë¡¬í”„íŠ¸ë¥¼ í…œí”Œë¦¿ìœ¼ë¡œ ê´€ë¦¬
    prompt = ChatPromptTemplate.from_messages([
        SystemMessagePromptTemplate.from_template(PROMPTS["SEARCH_ROUTER_PROMPT"])
    ])
    
    # ChatOpenAI: OpenAIì˜ GPT ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì¸í„°í˜ì´ìŠ¤
    llm = ChatOpenAI(
        model="gpt-4o-mini",  # ë¹ ë¥´ê³  ì €ë ´í•œ ëª¨ë¸ (gpt-4ë³´ë‹¤ 10ë°° ì´ìƒ ì €ë ´)
        temperature=0         # ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •
                              # temperature=0: í•­ìƒ ë™ì¼í•œ ì§ˆë¬¸ì— ë™ì¼í•œ ë‹µë³€
                              # temperature=1: ë§¤ë²ˆ ë‹¤ë¥¸ ë‹µë³€ (ì°½ì˜ì ì´ì§€ë§Œ ë¶ˆì•ˆì •)
    )
    
    # Structured Output: LLMì˜ ì¶œë ¥ì„ Pydantic ëª¨ë¸ í˜•ì‹ìœ¼ë¡œ ê°•ì œ
    # ì¼ë°˜ LLM í˜¸ì¶œ: "ììœ  í…ìŠ¤íŠ¸" ë°˜í™˜ â†’ íŒŒì‹± ì˜¤ë¥˜ ê°€ëŠ¥ âŒ
    # Structured Output: SearchConfig í˜•ì‹ìœ¼ë¡œë§Œ ë°˜í™˜ â†’ ì•ˆì •ì  âœ…
    structured_llm = llm.with_structured_output(SearchConfig)
    
    # Chain ì—°ê²°: prompt | structured_llm
    chain = prompt | structured_llm
    

    # 3ë‹¨ê³„: Chain ì‹¤í–‰ ë° ê²°ê³¼ ë°˜í™˜
    # chain.invoke(): í”„ë¡¬í”„íŠ¸ë¥¼ LLMì— ì „ì†¡í•˜ê³  ê²°ê³¼ë¥¼ ë°›ìŒ
    # ë°˜í™˜ê°’: SearchConfig ê°ì²´ (Pydantic ëª¨ë¸)
    result = chain.invoke({"query": query})
    

    # 4ë‹¨ê³„: Role Bê°€ ì‚¬ìš©í•  í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    # Role B (Search Executor)ê°€ í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œí•´ì„œ ë°˜í™˜
    return {
        # í•µì‹¬ ì •ë³´ (Role Bê°€ ì‹¤ì œë¡œ ì‚¬ìš©)
        'sources': result.search_sources,        # ì–´ë””ì„œ ê²€ìƒ‰í• ì§€
        'top_k': result.top_k,                   # ëª‡ ê°œ ê°€ì ¸ì˜¬ì§€
        'search_method': result.search_method,   # ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ
        'filters': {},                           # ë©”íƒ€ë°ì´í„° í•„í„° (í–¥í›„ í™•ì¥)
        
        # ë””ë²„ê¹…/ë¶„ì„ìš© ì¶”ê°€ ì •ë³´ (ì„ íƒì‚¬í•­)
        # Role BëŠ” ë¬´ì‹œí•´ë„ ë˜ê³ , ë¡œê¹…/ë¶„ì„ ì‹œ ìœ ìš©
        '_analysis': {
            'query_type': result.query_type,    # ì§ˆë¬¸ ìœ í˜•
            'topic_keywords': result.topic_keywords,  # ì¶”ì¶œëœ í‚¤ì›Œë“œ
            'complexity': result.complexity           # ë‚œì´ë„
        }
    }


# ============================================================
# í…ŒìŠ¤íŠ¸ ì½”ë“œ (íŒŒì¼ì„ ì§ì ‘ ì‹¤í–‰í•  ë•Œë§Œ ë™ì‘)
# ============================================================

if __name__ == "__main__":
    # ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì§ˆë¬¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    test_querys = [
        "RAGê°€ ë­ì•¼?",                              # ML ê°œë… ì§ˆë¬¸ (basic)
        "ë”¥ëŸ¬ë‹ ëª¨ë¸ ìµœì í™” ë°©ë²•",                    # ML ê³ ê¸‰ ì§ˆë¬¸ (advanced)
        "iris ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ëŠ” ì½”ë“œ",               # Python ì½”ë“œ ì§ˆë¬¸ (basic)
        "Python list comprehension ë¬¸ë²•",          # Python ë¬¸ë²• ì§ˆë¬¸ (syntax)
        "RAG êµ¬í˜„í•  ë•Œ pandas DataFrame í™œìš©ë²•"     # ë³µí•© ì§ˆë¬¸ (ML + Python)
    ]
    
    # í…ŒìŠ¤íŠ¸ ê²°ê³¼ í—¤ë”
    print("=" * 80)
    print("Search Router - ì™„ì „ LLM ê¸°ë°˜ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # ê° ì§ˆë¬¸ì— ëŒ€í•´ ê²€ìƒ‰ ì„¤ì • ìƒì„± ë° ì¶œë ¥
    for query in test_querys:
        print(f"\nğŸ“Œ ì§ˆë¬¸: {query}")
        print("-" * 80)
        
        
        config = build_search_config(query)
        
       
        print(f"âœ… ê²€ìƒ‰ ëŒ€ìƒ: {config['sources']}")        # ì–´ë””ì„œ ê²€ìƒ‰í• ì§€
        print(f"ğŸ“Š ê²€ìƒ‰ ê°œìˆ˜: {config['top_k']}ê°œ")        # ëª‡ ê°œ ê°€ì ¸ì˜¬ì§€
        print(f"ğŸ” ê²€ìƒ‰ ë°©ë²•: {config['search_method']}")  # ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ
        
        # ë””ë²„ê¹…ìš© ë¶„ì„ ì •ë³´ ì¶œë ¥
        analysis = config['_analysis']
        print(f"\nğŸ’¡ ë¶„ì„ ì •ë³´:")
        print(f"   - ì§ˆë¬¸ ìœ í˜•: {analysis['query_type']}")       # concept/code/syntax
        print(f"   - ì£¼ìš” í‚¤ì›Œë“œ: {', '.join(analysis['topic_keywords'])}")  # ì¶”ì¶œëœ í‚¤ì›Œë“œ
        print(f"   - ë‚œì´ë„: {analysis['complexity']}")             # basic/intermediate/advanced
        print("=" * 80)

