
## 하이브리드 검색(벡터 + 키워드 + BM25)

### 목표
- **강의 노트(lecture)** + **Python 공식문서(python_doc, RST)** 를 동시에 활용하는 RAG에서 품질을 올리는 것.

---

### 핵심 아이디어 (Search Agent 기준)
- **하이브리드 점수로 재랭킹**: Qdrant 벡터 검색 결과에 대해
  - **Vector score**(의미 유사도) +
  - **Keyword matching**(정확 용어 포함 여부) +
  - **BM25**(키워드 빈도/문서 길이 기반 sparse 점수)
  를 **가중합**으로 합쳐 최종 점수를 만듦.

- **가중치(동적)**:
  - 일반 쿼리: vector 0.6 / keyword 0.2 / bm25 0.2  
  - 단일 단어: vector 0.4 / keyword 0.3 / bm25 0.3 (정확 용어 매칭 강화)

---
### 키워드 매칭 (Keyword Matching)

#### 개념
**정확한 단어/용어**가 문서에 포함되어 있는지 확인하여 점수를 부여하는 방법입니다.

#### 작동 원리
1. 질문에서 키워드 추출 (공백 기준, 2글자 이상)
2. 각 문서에서 키워드 포함 여부 확인
   - 정확한 단어 매칭 (우선순위 높음)
   - 부분 문자열 매칭 (예: "trimming"이 "trimming_history"에 포함)
3. 매칭된 키워드 비율로 점수 계산 (0.0 ~ 1.0)

#### 점수 계산 방식
```python
# 키워드 매칭 점수 = 매칭된 키워드 가중치 합 / 전체 키워드 가중치 합
matched_count = sum(키워드별_가중치 for 매칭된_키워드)
total_weight = sum(키워드별_가중치 for 모든_키워드)
keyword_score = matched_count / total_weight
```
---
### BM25 (Best Matching 25)

#### 개념
**통계적 유사도**를 기반으로 검색하는 방법으로, TF-IDF의 개선 버전입니다. 문서 길이 정규화를 포함하여 더 정확한 점수를 계산합니다.

#### 작동 원리
1. **TF (Term Frequency)**: 키워드가 문서에 나타나는 빈도
2. **IDF (Inverse Document Frequency)**: 키워드가 드물수록 높은 점수
3. **문서 길이 정규화**: 긴 문서는 불리하지 않도록 정규화
4. 세 가지를 결합하여 최종 점수 계산
---
  
### 왜 top_k를 확장(candidate_k)하나?
- 하이브리드는 “벡터 점수 상위 문서”만 보면 **정확한 키워드가 들어간 문서**를 놓칠 수 있음.
- 벡터 검색은 의미적 유사도 중심이라서, 질문의 핵심 키워드를 정확히 포함한 문서라도 문맥이 다르면 점수가 낮아 상위 후보에서 탈락할 수 있기 때문이다. 
- 그래서 **벡터 단계에서 후보를 넉넉히 확보**하고(예: `candidate_k = top_k*4~6`),
  그 후보들만 **하이브리드 점수로 재정렬**해서 최종 top_k를 반환 → **recall/정확도 동시 개선**.


---

### 듀얼 쿼리 + Fallback (python_doc 최적화)
- python_doc는 영어 문서라 **한글 질문이면 “영어 키워드 검색”을 기본**으로 사용.
- 번역(영어 키워드) 결과가 약하면(최고 점수 < 0.45) **한글 원문으로 fallback 검색**을 추가해 안전장치 확보.
---

### 전처리/인제스트(검색 품질을 위한 문서 강화)
- RST(python_doc): RST 노이즈 제거 + 섹션 기반 청킹 + `[API]/[KEYWORDS]/[TITLE]/[H1]/[H2]` 프리픽스 주입
- lecture: 마크다운/코드 노이즈 제거 + 너무 짧은 셀 제거 + `[강의]/[섹션]` 문맥 프리픽스 주입

---

